{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "assignment_w5_c1_template.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sAT2lbC7wkR"
      },
      "source": [
        "Week 5, Assignment C1:\n",
        "\n",
        "Logistic Regression with Yahoo! Finance API in Python\n",
        "\n",
        "In this notebook, we will study Logistic Regression using the Yahoo! Finance API in Python.\n",
        "\n",
        "Please complete the lines bellow where you see \"#TODO\".\n",
        "\n",
        "do this first\n",
        "in the anaconda prompt  or in the Google Colab\n",
        "\n",
        "pip install pandas-datareader\n",
        "pip install yfinance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSe6c-xU7yvv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62250dfe-9705-4d69-9a7e-ec3ce410a874"
      },
      "source": [
        "!pip install yfinance"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.7/dist-packages (0.1.64)\n",
            "Requirement already satisfied: lxml>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from yfinance) (4.6.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.19.5)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance) (0.0.9)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.7/dist-packages (from yfinance) (2.23.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24->yfinance) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24->yfinance) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24->yfinance) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkePuN1h7wk3"
      },
      "source": [
        "#Objective 1.\n",
        "#Use this cell to import the Numpy (as np), Pandas (as pd), and YFinance (as yf) packages.\n",
        "import datetime as dt\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "\n",
        "#Our work will also require some components of the Sklearn and Pandas_Datareader packages as imported below:\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from pandas_datareader import data as pdr\n",
        "yf.pdr_override()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifHcUVwF7wlL"
      },
      "source": [
        "#Objective 2.\n",
        "#Select a stock symbol for a stock whose historical data is available on the Yahoo! Finance website.  Store the\n",
        "#string of your chosen symbol to the new variable \"stock_symbol\".\n",
        "start = dt.datetime(2020,1,1)\n",
        "end = dt.datetime.now()\n",
        "\n",
        "stock_symbol = ['DOGE-USD']"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UP7UaXwI7wlb",
        "outputId": "e16a43e0-3fbc-4646-c88d-4de76c6d0e39"
      },
      "source": [
        "#Objective 3.\n",
        "#Use the function \"pdr.get_data_yahoo(stock_symbol, start_date, end_date)\" to generate a Pandas dataframe of\n",
        "#historical stock data for your chosen stock.  Retain only the first four columns of the dataframe.  Be sure to \n",
        "#drop any rows containing NaN's, and take a peek at the resulting dataframe to make sure everything looks good.\n",
        "deletd_column =[]\n",
        "df = pdr.get_data_yahoo(stock_symbol, start, end).dropna()\n",
        "df = df[[\"Open\",\"Adj Close\"]]\n",
        "\n",
        "#df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "19KRAOpf7wls",
        "outputId": "96169e76-ff17-4374-b61e-eb1cba6920d8"
      },
      "source": [
        "#Objective 4.\n",
        "#Use the historical data to define some predictor variables.  Add these variables to the dataframe.  Include, at a\n",
        "#minimum, (Predictor.I) the rolling average closing price over the past fifteen (15) days and (Predictor.II) the\n",
        "#change in opening price over the past one (1) day.  Be sure to again drop any rows containing NaN's, and take a\n",
        "#peek at the resulting dataframe to make sure everything looks good.  Store the dataframe as the new variable \"X\".\n",
        "\n",
        "df['Close_15_Rolling'] = df['Adj Close'].rolling(window=15).mean() \n",
        "df['Open_1_Change'] = df['Open'].shift(1)\n",
        "df=df.dropna()\n",
        "X=df\n",
        "X"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Close_15_Rolling</th>\n",
              "      <th>Open_1_Change</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2020-01-15</th>\n",
              "      <td>0.002468</td>\n",
              "      <td>0.002369</td>\n",
              "      <td>0.002303</td>\n",
              "      <td>0.002358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-01-16</th>\n",
              "      <td>0.002372</td>\n",
              "      <td>0.002345</td>\n",
              "      <td>0.002323</td>\n",
              "      <td>0.002468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-01-17</th>\n",
              "      <td>0.002346</td>\n",
              "      <td>0.002490</td>\n",
              "      <td>0.002356</td>\n",
              "      <td>0.002372</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-01-18</th>\n",
              "      <td>0.002490</td>\n",
              "      <td>0.002507</td>\n",
              "      <td>0.002380</td>\n",
              "      <td>0.002346</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-01-19</th>\n",
              "      <td>0.002514</td>\n",
              "      <td>0.002405</td>\n",
              "      <td>0.002391</td>\n",
              "      <td>0.002490</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-11-06</th>\n",
              "      <td>0.261264</td>\n",
              "      <td>0.261898</td>\n",
              "      <td>0.268313</td>\n",
              "      <td>0.263655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-11-07</th>\n",
              "      <td>0.261971</td>\n",
              "      <td>0.266315</td>\n",
              "      <td>0.269285</td>\n",
              "      <td>0.261264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-11-08</th>\n",
              "      <td>0.266728</td>\n",
              "      <td>0.282359</td>\n",
              "      <td>0.269639</td>\n",
              "      <td>0.261971</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-11-09</th>\n",
              "      <td>0.282539</td>\n",
              "      <td>0.273526</td>\n",
              "      <td>0.270227</td>\n",
              "      <td>0.266728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-11-10</th>\n",
              "      <td>0.274031</td>\n",
              "      <td>0.270110</td>\n",
              "      <td>0.271186</td>\n",
              "      <td>0.282539</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>662 rows Ã— 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                Open  Adj Close  Close_15_Rolling  Open_1_Change\n",
              "Date                                                            \n",
              "2020-01-15  0.002468   0.002369          0.002303       0.002358\n",
              "2020-01-16  0.002372   0.002345          0.002323       0.002468\n",
              "2020-01-17  0.002346   0.002490          0.002356       0.002372\n",
              "2020-01-18  0.002490   0.002507          0.002380       0.002346\n",
              "2020-01-19  0.002514   0.002405          0.002391       0.002490\n",
              "...              ...        ...               ...            ...\n",
              "2021-11-06  0.261264   0.261898          0.268313       0.263655\n",
              "2021-11-07  0.261971   0.266315          0.269285       0.261264\n",
              "2021-11-08  0.266728   0.282359          0.269639       0.261971\n",
              "2021-11-09  0.282539   0.273526          0.270227       0.266728\n",
              "2021-11-10  0.274031   0.270110          0.271186       0.282539\n",
              "\n",
              "[662 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pA_m0Nyg7wmC",
        "outputId": "794afa8e-82f4-4749-8e1c-726cf2f432e8"
      },
      "source": [
        "#Objective 5.\n",
        "#Define the target or dependent variable to be one (1) if the change in closing price over the past one (1) day is\n",
        "#nonnegative and negative one (-1) if the change in closing price over the past one (1) day is negative.  This\n",
        "#variable's values should be forward-looking (i.e., you should subtract today's price from tomorrow's price rather\n",
        "#than subtracting yesterday's price from today's price).  Store the resulting values as the new variable \"y\".  You\n",
        "#may find the \"np.where(*args)\" function to be useful.  Look it up in Numpy documentation for support.\n",
        "#np.where(a < 5, a, 10*a)\n",
        "y = np.where(df[\"Adj Close\"].shift(-1) - df[\"Adj Close\"] >= 0, 1, -1)\n",
        "y"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1,  1,  1, -1, -1,  1, -1, -1,  1, -1,  1,  1,  1, -1,  1, -1,  1,\n",
              "        1, -1,  1,  1,  1,  1,  1,  1, -1,  1,  1, -1,  1, -1, -1, -1,  1,\n",
              "       -1,  1, -1, -1,  1, -1, -1, -1, -1, -1, -1,  1,  1,  1, -1,  1, -1,\n",
              "       -1, -1,  1, -1, -1, -1,  1, -1,  1, -1,  1, -1,  1,  1,  1, -1,  1,\n",
              "        1, -1,  1, -1, -1, -1,  1, -1,  1,  1, -1,  1, -1,  1,  1,  1,  1,\n",
              "       -1,  1,  1, -1,  1, -1,  1,  1, -1, -1, -1,  1,  1,  1,  1,  1, -1,\n",
              "       -1,  1, -1,  1,  1, -1, -1,  1,  1,  1, -1, -1, -1, -1,  1,  1,  1,\n",
              "       -1,  1,  1,  1, -1, -1, -1,  1,  1, -1,  1, -1,  1,  1,  1,  1, -1,\n",
              "        1, -1,  1,  1, -1, -1,  1, -1, -1,  1, -1,  1,  1, -1, -1,  1, -1,\n",
              "       -1, -1,  1,  1,  1,  1, -1, -1, -1, -1,  1, -1,  1,  1,  1, -1, -1,\n",
              "        1,  1,  1,  1, -1, -1,  1, -1, -1,  1, -1, -1,  1,  1, -1, -1,  1,\n",
              "       -1,  1, -1,  1,  1, -1,  1, -1,  1, -1,  1, -1,  1,  1, -1,  1, -1,\n",
              "       -1, -1,  1, -1,  1,  1,  1, -1, -1,  1, -1, -1,  1, -1,  1, -1,  1,\n",
              "       -1, -1, -1,  1,  1,  1, -1,  1, -1, -1,  1, -1,  1,  1, -1,  1,  1,\n",
              "        1,  1, -1,  1,  1, -1, -1, -1, -1, -1, -1,  1, -1,  1,  1,  1, -1,\n",
              "       -1,  1, -1, -1, -1,  1,  1, -1, -1, -1,  1,  1,  1, -1, -1,  1, -1,\n",
              "        1,  1,  1,  1,  1, -1, -1,  1,  1, -1, -1, -1,  1, -1,  1, -1,  1,\n",
              "        1,  1,  1, -1,  1, -1,  1,  1,  1,  1, -1,  1,  1,  1, -1,  1,  1,\n",
              "        1, -1,  1,  1, -1, -1,  1,  1,  1,  1, -1,  1,  1, -1,  1, -1, -1,\n",
              "       -1, -1, -1, -1,  1,  1, -1, -1,  1,  1,  1,  1,  1,  1, -1, -1,  1,\n",
              "        1, -1,  1,  1, -1,  1,  1,  1,  1, -1, -1,  1,  1, -1,  1,  1, -1,\n",
              "       -1, -1,  1,  1, -1, -1, -1,  1, -1, -1, -1,  1,  1,  1, -1, -1, -1,\n",
              "        1,  1, -1,  1, -1, -1,  1,  1, -1,  1,  1,  1, -1,  1, -1,  1, -1,\n",
              "       -1, -1, -1, -1,  1, -1, -1,  1, -1, -1,  1, -1,  1, -1, -1,  1, -1,\n",
              "        1, -1, -1,  1,  1,  1, -1, -1, -1, -1,  1, -1, -1,  1, -1, -1,  1,\n",
              "        1, -1, -1, -1, -1, -1,  1,  1, -1,  1, -1, -1,  1, -1, -1,  1,  1,\n",
              "        1, -1,  1,  1,  1,  1, -1,  1,  1,  1,  1, -1,  1,  1, -1, -1, -1,\n",
              "       -1,  1, -1,  1,  1,  1, -1,  1,  1, -1,  1,  1,  1, -1,  1, -1, -1,\n",
              "       -1,  1, -1,  1,  1, -1,  1, -1, -1, -1,  1, -1, -1, -1,  1, -1,  1,\n",
              "       -1, -1, -1, -1,  1,  1,  1, -1, -1, -1, -1, -1, -1,  1, -1, -1, -1,\n",
              "        1,  1, -1, -1, -1, -1, -1, -1, -1,  1,  1,  1, -1,  1,  1, -1,  1,\n",
              "       -1, -1,  1,  1,  1, -1,  1, -1, -1,  1, -1,  1, -1, -1, -1, -1, -1,\n",
              "        1, -1, -1, -1,  1,  1,  1,  1,  1,  1,  1, -1, -1,  1, -1, -1, -1,\n",
              "       -1,  1, -1,  1,  1, -1,  1,  1,  1, -1,  1,  1,  1, -1, -1,  1,  1,\n",
              "        1, -1, -1,  1, -1,  1, -1,  1, -1, -1, -1,  1,  1,  1,  1,  1,  1,\n",
              "       -1, -1,  1, -1, -1,  1,  1, -1,  1,  1, -1, -1,  1, -1, -1, -1,  1,\n",
              "       -1, -1, -1, -1, -1, -1,  1,  1,  1, -1,  1,  1,  1,  1, -1,  1,  1,\n",
              "       -1,  1, -1,  1, -1,  1,  1,  1,  1, -1,  1, -1,  1,  1,  1, -1, -1,\n",
              "       -1,  1, -1, -1,  1, -1,  1, -1, -1, -1,  1,  1,  1, -1, -1, -1])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2TQ3IqZ7wmM"
      },
      "source": [
        "#Objective 6.\n",
        "#Split the data into training and test sets, putting the first seventy percent (70%) of the data in the training\n",
        "#set.\n",
        "\n",
        "#y_data = X[\"Adj Close_Change\"] \n",
        "#x_data = X.drop(\"Adj Close_Change\", axis = 1)\n",
        "\n",
        "\n",
        "index = int(0.7*len(X))\n",
        "X_train,X_test,y_train,y_test = X[:index], X[index:], y[:index], y[index:]\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sGZTUgV7wmT"
      },
      "source": [
        "#Objective 7.\n",
        "#Instantiate the Logistic Regression model object, and use its \".fit(*args)\" method to fit the model to the \n",
        "#training data.\n",
        "logistic = LogisticRegression()\n",
        "logistic = logistic.fit(X_train,y_train)\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "-3Lr7Mum7wma",
        "outputId": "de4cd47d-f970-49df-d3c6-55a3a11ea561"
      },
      "source": [
        "#Objective 8.\n",
        "#Examine the model's coefficients by using its \".coef_\" method.\n",
        "\n",
        "pd.DataFrame(zip(X.columns, np.transpose(logistic.coef_)))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Open</td>\n",
              "      <td>[-0.2605769360409]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Adj Close</td>\n",
              "      <td>[-0.3565487361464747]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Close_15_Rolling</td>\n",
              "      <td>[-0.24997749258199864]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Open_1_Change</td>\n",
              "      <td>[-0.2760831545767646]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  0                       1\n",
              "0              Open      [-0.2605769360409]\n",
              "1         Adj Close   [-0.3565487361464747]\n",
              "2  Close_15_Rolling  [-0.24997749258199864]\n",
              "3     Open_1_Change   [-0.2760831545767646]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1kqcLq87wmd",
        "outputId": "f385e056-c18b-49c9-e5ea-b487bd8d73af"
      },
      "source": [
        "#Objective 9.\n",
        "#Use the model's \".predict_proba(*args)\" and \".predict(*args)\" methods to generate predictions over the test set.\n",
        "\n",
        "probabilities = logistic.predict_proba(X_test)\n",
        "predictions = logistic.predict(X_test)\n",
        "print(probabilities)\n",
        "print(predictions)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.55123128 0.44876872]\n",
            " [0.55222941 0.44777059]\n",
            " [0.5591402  0.4408598 ]\n",
            " [0.56159688 0.43840312]\n",
            " [0.56734433 0.43265567]\n",
            " [0.5731425  0.4268575 ]\n",
            " [0.57766477 0.42233523]\n",
            " [0.58634004 0.41365996]\n",
            " [0.59848515 0.40151485]\n",
            " [0.62009573 0.37990427]\n",
            " [0.62808758 0.37191242]\n",
            " [0.64137748 0.35862252]\n",
            " [0.64073948 0.35926052]\n",
            " [0.6401048  0.3598952 ]\n",
            " [0.6235692  0.3764308 ]\n",
            " [0.61663482 0.38336518]\n",
            " [0.602614   0.397386  ]\n",
            " [0.60874967 0.39125033]\n",
            " [0.61483216 0.38516784]\n",
            " [0.62180504 0.37819496]\n",
            " [0.62440152 0.37559848]\n",
            " [0.61955348 0.38044652]\n",
            " [0.61742961 0.38257039]\n",
            " [0.60208328 0.39791672]\n",
            " [0.59695194 0.40304806]\n",
            " [0.58707013 0.41292987]\n",
            " [0.5862695  0.4137305 ]\n",
            " [0.57829137 0.42170863]\n",
            " [0.57914772 0.42085228]\n",
            " [0.57835895 0.42164105]\n",
            " [0.58116964 0.41883036]\n",
            " [0.57828159 0.42171841]\n",
            " [0.57487623 0.42512377]\n",
            " [0.57036616 0.42963384]\n",
            " [0.56740232 0.43259768]\n",
            " [0.56805647 0.43194353]\n",
            " [0.57289308 0.42710692]\n",
            " [0.58175182 0.41824818]\n",
            " [0.58636581 0.41363419]\n",
            " [0.58636495 0.41363505]\n",
            " [0.58299896 0.41700104]\n",
            " [0.58113713 0.41886287]\n",
            " [0.57734022 0.42265978]\n",
            " [0.57435382 0.42564618]\n",
            " [0.57267806 0.42732194]\n",
            " [0.57179868 0.42820132]\n",
            " [0.5711932  0.4288068 ]\n",
            " [0.5689353  0.4310647 ]\n",
            " [0.56918223 0.43081777]\n",
            " [0.57027316 0.42972684]\n",
            " [0.57091645 0.42908355]\n",
            " [0.56864547 0.43135453]\n",
            " [0.56681505 0.43318495]\n",
            " [0.56429679 0.43570321]\n",
            " [0.56248688 0.43751312]\n",
            " [0.56021127 0.43978873]\n",
            " [0.54955221 0.45044779]\n",
            " [0.54308583 0.45691417]\n",
            " [0.54011837 0.45988163]\n",
            " [0.54617886 0.45382114]\n",
            " [0.54860219 0.45139781]\n",
            " [0.54907546 0.45092454]\n",
            " [0.54939106 0.45060894]\n",
            " [0.55023179 0.44976821]\n",
            " [0.55125017 0.44874983]\n",
            " [0.55006277 0.44993723]\n",
            " [0.54876464 0.45123536]\n",
            " [0.5472838  0.4527162 ]\n",
            " [0.54658979 0.45341021]\n",
            " [0.54658943 0.45341057]\n",
            " [0.54516148 0.45483852]\n",
            " [0.54465726 0.45534274]\n",
            " [0.54304156 0.45695844]\n",
            " [0.54104685 0.45895315]\n",
            " [0.54015521 0.45984479]\n",
            " [0.53916387 0.46083613]\n",
            " [0.53970593 0.46029407]\n",
            " [0.53850934 0.46149066]\n",
            " [0.53718828 0.46281172]\n",
            " [0.53560982 0.46439018]\n",
            " [0.53352299 0.46647701]\n",
            " [0.53114524 0.46885476]\n",
            " [0.53041174 0.46958826]\n",
            " [0.52985304 0.47014696]\n",
            " [0.5294661  0.4705339 ]\n",
            " [0.52810027 0.47189973]\n",
            " [0.52888976 0.47111024]\n",
            " [0.52991098 0.47008902]\n",
            " [0.53159406 0.46840594]\n",
            " [0.5320125  0.4679875 ]\n",
            " [0.53238482 0.46761518]\n",
            " [0.53313625 0.46686375]\n",
            " [0.53369409 0.46630591]\n",
            " [0.53421786 0.46578214]\n",
            " [0.5343021  0.4656979 ]\n",
            " [0.53470157 0.46529843]\n",
            " [0.53500106 0.46499894]\n",
            " [0.53492401 0.46507599]\n",
            " [0.53465235 0.46534765]\n",
            " [0.53377444 0.46622556]\n",
            " [0.53387187 0.46612813]\n",
            " [0.53372232 0.46627768]\n",
            " [0.53442904 0.46557096]\n",
            " [0.53984361 0.46015639]\n",
            " [0.54218523 0.45781477]\n",
            " [0.54641921 0.45358079]\n",
            " [0.54623062 0.45376938]\n",
            " [0.54835642 0.45164358]\n",
            " [0.54903116 0.45096884]\n",
            " [0.551858   0.448142  ]\n",
            " [0.55417232 0.44582768]\n",
            " [0.56097441 0.43902559]\n",
            " [0.56308303 0.43691697]\n",
            " [0.56342333 0.43657667]\n",
            " [0.56153724 0.43846276]\n",
            " [0.56206763 0.43793237]\n",
            " [0.56468701 0.43531299]\n",
            " [0.56580128 0.43419872]\n",
            " [0.56587058 0.43412942]\n",
            " [0.56561037 0.43438963]\n",
            " [0.56325856 0.43674144]\n",
            " [0.5620724  0.4379276 ]\n",
            " [0.55828464 0.44171536]\n",
            " [0.55935683 0.44064317]\n",
            " [0.5586045  0.4413955 ]\n",
            " [0.55935291 0.44064709]\n",
            " [0.55738232 0.44261768]\n",
            " [0.55684837 0.44315163]\n",
            " [0.55799082 0.44200918]\n",
            " [0.55956553 0.44043447]\n",
            " [0.56064184 0.43935816]\n",
            " [0.56090893 0.43909107]\n",
            " [0.56252669 0.43747331]\n",
            " [0.56317811 0.43682189]\n",
            " [0.55875833 0.44124167]\n",
            " [0.555043   0.444957  ]\n",
            " [0.55049777 0.44950223]\n",
            " [0.54914183 0.45085817]\n",
            " [0.54837983 0.45162017]\n",
            " [0.54827099 0.45172901]\n",
            " [0.5474878  0.4525122 ]\n",
            " [0.54747811 0.45252189]\n",
            " [0.54726469 0.45273531]\n",
            " [0.54735487 0.45264513]\n",
            " [0.5470157  0.4529843 ]\n",
            " [0.54640507 0.45359493]\n",
            " [0.54534162 0.45465838]\n",
            " [0.54215901 0.45784099]\n",
            " [0.53904291 0.46095709]\n",
            " [0.53884674 0.46115326]\n",
            " [0.5397144  0.4602856 ]\n",
            " [0.53981296 0.46018704]\n",
            " [0.5386142  0.4613858 ]\n",
            " [0.5370418  0.4629582 ]\n",
            " [0.53614793 0.46385207]\n",
            " [0.53509997 0.46490003]\n",
            " [0.53455456 0.46544544]\n",
            " [0.53476554 0.46523446]\n",
            " [0.53683862 0.46316138]\n",
            " [0.53797665 0.46202335]\n",
            " [0.53912906 0.46087094]\n",
            " [0.54078535 0.45921465]\n",
            " [0.5434221  0.4565779 ]\n",
            " [0.54593945 0.45406055]\n",
            " [0.54582239 0.45417761]\n",
            " [0.54541152 0.45458848]\n",
            " [0.54506347 0.45493653]\n",
            " [0.54389727 0.45610273]\n",
            " [0.54326105 0.45673895]\n",
            " [0.54186394 0.45813606]\n",
            " [0.54236829 0.45763171]\n",
            " [0.54252639 0.45747361]\n",
            " [0.54322496 0.45677504]\n",
            " [0.54368018 0.45631982]\n",
            " [0.54411017 0.45588983]\n",
            " [0.54531177 0.45468823]\n",
            " [0.54586052 0.45413948]\n",
            " [0.54713678 0.45286322]\n",
            " [0.54652182 0.45347818]\n",
            " [0.54652937 0.45347063]\n",
            " [0.54651458 0.45348542]\n",
            " [0.54946168 0.45053832]\n",
            " [0.55055732 0.44944268]\n",
            " [0.55081952 0.44918048]\n",
            " [0.54794785 0.45205215]\n",
            " [0.55196433 0.44803567]\n",
            " [0.55385503 0.44614497]\n",
            " [0.55576172 0.44423828]\n",
            " [0.55496239 0.44503761]\n",
            " [0.55378871 0.44621129]\n",
            " [0.55423034 0.44576966]\n",
            " [0.55354267 0.44645733]\n",
            " [0.55286768 0.44713232]\n",
            " [0.5521349  0.4478651 ]\n",
            " [0.55171927 0.44828073]\n",
            " [0.55205116 0.44794884]\n",
            " [0.55384178 0.44615822]\n",
            " [0.55444238 0.44555762]\n",
            " [0.55473136 0.44526864]]\n",
            "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzc7ttI77wmg",
        "outputId": "5c0a50ee-1644-49ff-9f76-df030174912c"
      },
      "source": [
        "#Objective 10.\n",
        "#Use the function \"metrics.confusion_matrix(*args)\" to create a confusion matrix comparing the predicted and true\n",
        "#classification labels over the test set.\n",
        "\n",
        "confusion_matrix =metrics.confusion_matrix(y_test,predictions)\n",
        "confusion_matrix\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[104,   0],\n",
              "       [ 95,   0]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUcRn0bH7wmk",
        "outputId": "2b733bdb-0549-42f1-c597-6a4b2f3ab3bf"
      },
      "source": [
        "#Objective 11.\n",
        "#Calculate the model's accuracy on the test set using its \".score(*args)\" method.\n",
        "from sklearn.metrics import accuracy_score \n",
        "accuracy = accuracy_score(y_test,predictions)\n",
        "accuracy\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5226130653266332"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWYIf5m-7wmo",
        "outputId": "c7ef7e6e-962c-4889-99f9-6e3c55084a16"
      },
      "source": [
        "#Objective 12.\n",
        "#Use five-fold cross validation to cross-check the accuracy of the model over different held-out test sets.  This\n",
        "#is where you should use the function \"cross_val_score(*args)\".\n",
        "\n",
        "cross_val = cross_val_score(logistic,X, y, cv=5)\n",
        "print(cross_val)\n",
        "print(cross_val.mean())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.5037594  0.5037594  0.50757576 0.59848485 0.49242424]\n",
            "0.5212007290954659\n"
          ]
        }
      ]
    }
  ]
}